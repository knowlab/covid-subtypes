{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "def preprocess(all_data):\n",
    "#     Split the dataset into features and labels (clusters) - so we can normalise the features but not the labels\n",
    "    all_X = all_data.iloc[:,2:len(all_data.columns)-1]\n",
    "    all_y = all_data['cluster']\n",
    "    \n",
    "    # normalise the data so we have unit variance and mean 0 using built-in preprocessing method in sklearn\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    all_X= pd.DataFrame(scaler.fit_transform(all_X),columns=all_X.columns)\n",
    "    \n",
    "#     reset the indexes otherwise it was breaking\n",
    "    all_X= all_X.reset_index()\n",
    "    all_y = all_y.reset_index()\n",
    "    all_X = all_X.drop(columns=['index'])\n",
    "    all_y = all_y.drop(columns=['index'])\n",
    "    \n",
    "    #prepare data for training a model by splitting into training and testing data \n",
    "    return (all_X, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the class names\n",
    "class_names = [4,2,0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up performance metrics calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#method to compute performance metrics \n",
    "def performance_metrics(y_true, y_pred):\n",
    "    #create a confusion matrix from results \n",
    "    cnf_matrix  = metrics.confusion_matrix(y_true, y_pred, labels=class_names, sample_weight=None, normalize=None)\n",
    "#     # average over all classes to find overall fp,fn,tp,tn\n",
    "#     FP = np.sum(cnf_matrix, axis=0) - np.diag(cnf_matrix)\n",
    "#     FN = np.sum(cnf_matrix, axis=1) - np.diag(cnf_matrix)\n",
    "#     TP = np.diag(cnf_matrix)\n",
    "#     TN = np.sum(cnf_matrix) - (FP + FN + TP)\n",
    "        \n",
    "    #find out if each predicted label is right \n",
    "    correct_labels = 0\n",
    "    for i, true_label in enumerate(y_true):\n",
    "        if (true_label == y_pred[i]):\n",
    "            correct_labels += 1\n",
    "\n",
    "    #calculate overall accuracy\n",
    "#     acc = np.round(correct_labels/y_pred.shape[0],2)\n",
    "        \n",
    "    # tp rate is the same as recall \n",
    "#     recall = np.sum(TP)/(np.sum(TP)+np.sum(FN))\n",
    "#     FP_rate = np.sum(FP)/(np.sum(FP)+np.sum(TN))  \n",
    "#     precision = np.sum(TP)/(np.sum(TP)+np.sum(FP)) \n",
    "#     f_measure = (2*precision*recall)/(precision + recall) \n",
    "\n",
    "    metrics_dict = metrics.classification_report(y_true,y_pred,output_dict=True)\n",
    "    avg_metrics = metrics_dict['macro avg']\n",
    "#     print(metrics_dict.values())\n",
    "    recall = avg_metrics['recall']\n",
    "    precision = avg_metrics['precision']\n",
    "    f_measure = avg_metrics['f1-score']\n",
    "    acc = metrics_dict['accuracy']\n",
    "    \n",
    "    print(metrics.classification_report(y_true,y_pred))\n",
    "    \n",
    "    return (acc, recall, precision, f_measure,\n",
    "            cnf_matrix,)\n",
    "\n",
    "#      np.round(cnf_matrix/cnf_matrix.sum(axis=1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "#method to plot the confusion matrix \n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix, index = [i for i in class_names], columns = [i for i in class_names])\n",
    "    plt.figure()\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use k-fold cross validation to evaluate the effectiveness of our models, where each 'fold' results in a slightly different train/test split, allowing us to see how the model beaves with different data. We can compute various metrics about the model performance, and from these results, we can choose the most effective classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "\n",
    "def cross_val(all_X, all_y, class_names, downsampling, upsampling, down_prop, up_prop, clf, printing):\n",
    "    print('cross-validating...')\n",
    "    k_val = 3\n",
    "    #use 3 splits \n",
    "    k_fold = model_selection.KFold(n_splits=k_val)\n",
    "    strat_k_fold = model_selection.StratifiedKFold(n_splits=k_val, shuffle=True)\n",
    "\n",
    "    #create empty arrays to store the results from each fold\n",
    "    #we can then average these to get the overall classifications and performance \n",
    "    accuracies = np.empty(k_val)\n",
    "    tp_rates = np.empty(k_val)\n",
    "    precisions = np.empty(k_val)\n",
    "    f_measures = np.empty(k_val)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    #split training data into training and validation sets\n",
    "    for train_indices, validation_indices in strat_k_fold.split(all_X, all_y):\n",
    "    #     print(X_train.index)\n",
    "        X_training = all_X.iloc[train_indices]\n",
    "        y_training = all_y.iloc[train_indices]\n",
    "        X_validate = all_X.iloc[validation_indices]\n",
    "        y_validate = all_y.iloc[validation_indices]\n",
    "        \n",
    "        # upsample the training data in each fold, if upsample = true\n",
    "        #with stratified k fold, better not to upsample, as it preserves percentage of samples for each class \n",
    "#         print('value counts: ', y_training.value_counts())\n",
    "\n",
    "        if(downsampling):\n",
    "#             print('downsampling...')\n",
    "            X_training, y_training = downsample(X_training, y_training, class_names, down_prop)\n",
    "            if (printing):\n",
    "                print('value counts: ', y_training.value_counts())\n",
    "\n",
    "        if (upsampling):\n",
    "#             print('upsampling...')\n",
    "            X_training, y_training = upsample(X_training, y_training, class_names, up_prop)\n",
    "            if (printing):\n",
    "                print('value counts:', y_training.value_counts())\n",
    "            \n",
    "        # fit classifier\n",
    "        clf.fit(X_training, y_training.values.ravel())\n",
    "        \n",
    "        #predict \n",
    "        y_predicted = clf.predict(X_validate)\n",
    "        y_true_val = y_validate.cluster\n",
    "        \n",
    "        #if we are using the decision tree classifier we may want to export the tree to look at it \n",
    "        from sklearn import tree\n",
    "\n",
    "        export_tree = False\n",
    "        if(export_tree):\n",
    "            for tree_in_forest in clf.estimators_:\n",
    "                if(export_tree):\n",
    "                    tree.export_graphviz(tree_in_forest, out_file=\"rotated_tree_eg.dot\",filled = True, \n",
    "                                         feature_names = X_training.columns, class_names=class_names,\n",
    "                                         rotate = True)\n",
    "        if (printing):\n",
    "            print(np.unique(y_predicted, return_counts=True))\n",
    "\n",
    "        #see how validation set performs \n",
    "        acc, recall, precision, f_measure, confusion_matrix = performance_metrics(y_true_val.values, y_predicted)\n",
    "\n",
    "        if (printing):\n",
    "            #print performance results for each fold\n",
    "            print(\"accuracy: \", acc)\n",
    "            print(\"true positive rate / recall: \", recall)\n",
    "            print(\"precision: \", precision)\n",
    "            print(\"f measure: \", f_measure)\n",
    "            plot_confusion_matrix(confusion_matrix, class_names)\n",
    "            print(\"----------\")\n",
    "\n",
    "        # store info for each fold \n",
    "        accuracies[count] = acc\n",
    "        tp_rates[count] = recall\n",
    "        precisions[count] = precision\n",
    "        f_measures[count] = f_measure\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    #average scores\n",
    "    cv_acc = np.mean(accuracies)\n",
    "    cv_tp = np.mean(tp_rates)\n",
    "    cv_precision = np.mean(precisions)\n",
    "    cv_f_measure = np.mean(f_measures)\n",
    "\n",
    "\n",
    "    print(\"overall average performance:\")\n",
    "    print(\"accuracy: \", cv_acc)\n",
    "    print(\"true positive rate/recall: \", cv_tp)\n",
    "    print(\"precision: \", cv_precision)\n",
    "    print(\"f measure: \", cv_f_measure)\n",
    "    \n",
    "    return X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to perform grid search to find the best parameters for the random forest classifier, uses cross-val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to implement this manually due to library constraints and difficulties with upsampling properly inside gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, pipeline, ensemble\n",
    "\n",
    "def grid_search_rand_forest(data_X, data_y,class_names, downsampling, upsampling, down_prop, up_prop):\n",
    "\n",
    "    best_f = 0.0\n",
    "    \n",
    "    # gridsearch for parameter optimisation\n",
    "    param_grid = { \n",
    "        'n_estimators': [5, 10, 15, 20, 30, 40, 60, 80],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'criterion' :['gini', 'entropy']}\n",
    "    \n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for max_features in param_grid['max_features']:\n",
    "                for min_samples_split in param_grid['min_samples_split']:\n",
    "                    for criterion in param_grid['criterion']:\n",
    "                        clf = ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, \n",
    "                                               min_samples_split=min_samples_split, criterion=criterion)\n",
    "\n",
    "                        X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, f_measure = cross_val(data_X, data_y, class_names, downsampling, upsampling, down_prop, up_prop, clf, printing=True)\n",
    "\n",
    "                        if(f_measure > best_f):\n",
    "                            best_f = f_measure\n",
    "                            best_clf = clf\n",
    "    \n",
    "    # Create grid search object\n",
    "#     clf = model_selection.GridSearchCV(estimator=ensemble.RandomForestClassifier(), param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "\n",
    "#     best_clf = clf.fit(data_X, data_y.values.ravel())\n",
    "\n",
    "#     gridsearch_results = pd.DataFrame(best_clf.cv_results_)\n",
    "\n",
    "    #sort according to overall rank score to find best params\n",
    "#     best_params_found = gridsearch_results.sort_values('rank_test_score').iloc[0]\n",
    "    print(best_clf)\n",
    "    \n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address class imbalance by removing some examples in most numerous classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(train_X, train_y, class_names, down_prop):\n",
    "    \n",
    "    train_data_and_labels = train_X.copy()\n",
    "    train_data_and_labels['cluster'] = train_y\n",
    "    \n",
    "    #find the largest class and the number of samples in training\n",
    "    value_counts = train_data_and_labels.cluster.value_counts()\n",
    "    max_val = max(value_counts)\n",
    "\n",
    "    most_numerous =  train_data_and_labels.cluster.value_counts().index[0]\n",
    "    big_cluster = train_data_and_labels[train_data_and_labels['cluster']==most_numerous]\n",
    "    new_train = train_data_and_labels[train_data_and_labels.cluster!=most_numerous]\n",
    "    #remove more individuals in largest class if limited classes, as class imbalance is bigger here\n",
    "    reduced_cluster = big_cluster.sample(replace=False, n=int(len(big_cluster)*down_prop), random_state=1)\n",
    "    train_down = new_train.append(reduced_cluster)\n",
    "    y_train_down = train_down['cluster']\n",
    "    X_train_down = train_down.iloc[:,0:len(train_down.columns)-1]        \n",
    "    \n",
    "    return X_train_down, y_train_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improves the prediction accuracy for the classes containing fewer individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample the least numerous classes\n",
    "def upsample(train_X, train_y, class_names, up_prop):\n",
    "    \n",
    "    train_data_and_labels = train_X.copy()\n",
    "    train_data_and_labels['cluster'] = train_y\n",
    "\n",
    "    #find the largest class and the number of samples in training\n",
    "    value_counts = train_data_and_labels.cluster.value_counts()\n",
    "    max_val = max(value_counts)\n",
    "        \n",
    "    #upsampling all the classes in training data \n",
    "    for cluster in class_names:\n",
    "        cluster_vals = train_data_and_labels[train_data_and_labels.cluster==cluster]\n",
    "        num_in_cluster = len(cluster_vals.index)\n",
    "        num_extra_samples = int(up_prop*(max_val - num_in_cluster))\n",
    "        new_samples = cluster_vals.sample(replace=True, n=num_extra_samples, random_state=1)\n",
    "        train_data_and_labels = train_data_and_labels.append(new_samples)\n",
    "            \n",
    "#     print(train_data_and_labels.cluster.value_counts())\n",
    "    \n",
    "    X_train_up = train_data_and_labels.iloc[:,0:len(train_data_and_labels.columns)-1]\n",
    "    y_train_up = train_data_and_labels['cluster']\n",
    "    \n",
    "    return X_train_up, y_train_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-axis clustering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now classify using the two-step clustering approach. First we use the clusters found using chapter codes, and then we use subclusters based on discharge data to find nuanced subclusters inside these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the data including imputed values for test results etc \n",
    "all_data = pd.read_csv('imputed_all_data.csv')\n",
    "parse_dates=['admission_date_structured']\n",
    "subclusters = pd.read_csv('subclusters.csv')\n",
    "# labels = pd.read_csv('chapter_codes_clusters3.csv')\n",
    "combined_clean = pd.read_csv('combined_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_and_labels_comorb = pd.merge(all_data, subclusters[['id','disch_4']],\n",
    "                           how='right', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comorbidities \n",
    "orig_data_and_labels = orig_data_and_labels_comorb.drop(columns=['morbidity_Diabetes','morbidity_COPD',\n",
    "                                                                 'morbidity_Hypertension','morbidity_Heartdisease',\n",
    "                                                                 'morbidity_Renaldisease','morbidity_Tumor',\n",
    "                                                                 'morbidity_Metabolicdisorders',\n",
    "                                                                 'morbidity_Respiratorydiseases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>smoking_structured</th>\n",
       "      <th>age</th>\n",
       "      <th>blood_sugar_d1_min</th>\n",
       "      <th>blood_sugar_d1_max</th>\n",
       "      <th>blood_sugar_d3_min</th>\n",
       "      <th>blood_sugar_d3_max</th>\n",
       "      <th>...</th>\n",
       "      <th>AlbumintoGlobulinRatio</th>\n",
       "      <th>Male</th>\n",
       "      <th>Consciousness</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Respiratoryrate</th>\n",
       "      <th>Redcelldistributionwidth</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>Lymphocyte(%)</th>\n",
       "      <th>disch_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100251</td>\n",
       "      <td>155.00000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.925083</td>\n",
       "      <td>5.956664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.382490</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>23.384615</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101019</td>\n",
       "      <td>151.00000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>3.902008</td>\n",
       "      <td>4.507097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129046</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.424242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102696</td>\n",
       "      <td>169.00000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>5.538094</td>\n",
       "      <td>7.640623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367413</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>32.266155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101588</td>\n",
       "      <td>161.00000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.939551</td>\n",
       "      <td>4.895466</td>\n",
       "      <td>4.694930</td>\n",
       "      <td>4.862858</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125873</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>25.101747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100358</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.793085</td>\n",
       "      <td>6.349398</td>\n",
       "      <td>5.576803</td>\n",
       "      <td>5.064091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006937</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15.538462</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>2792</td>\n",
       "      <td>101460</td>\n",
       "      <td>172.00000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>5.230405</td>\n",
       "      <td>3.933495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>100.326822</td>\n",
       "      <td>66.389026</td>\n",
       "      <td>32.307692</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>100047</td>\n",
       "      <td>172.00000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.091314</td>\n",
       "      <td>7.067830</td>\n",
       "      <td>4.062333</td>\n",
       "      <td>4.329303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263107</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>101.593761</td>\n",
       "      <td>78.039515</td>\n",
       "      <td>18.589744</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>103038</td>\n",
       "      <td>174.00000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>5.489082</td>\n",
       "      <td>5.853361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>37.792496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>100889</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.339569</td>\n",
       "      <td>4.426759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>14.313725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>100008</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.499901</td>\n",
       "      <td>5.495763</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>6.228706</td>\n",
       "      <td>...</td>\n",
       "      <td>1.464453</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>117.223687</td>\n",
       "      <td>67.975513</td>\n",
       "      <td>27.307692</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id     Height  Weight  smoking_structured   age  \\\n",
       "0              0  100251  155.00000    60.0                   0  62.0   \n",
       "1              1  101019  151.00000    63.0                   0  72.0   \n",
       "2              2  102696  169.00000    80.0                   0  63.0   \n",
       "3              3  101588  161.00000    57.0                   0  39.0   \n",
       "4              4  100358  164.75961    65.0                   0  62.0   \n",
       "...          ...     ...        ...     ...                 ...   ...   \n",
       "2792        2792  101460  172.00000    72.0                   0  49.0   \n",
       "2793        2793  100047  172.00000    75.0                   0  45.0   \n",
       "2794        2794  103038  174.00000    72.0                   0  56.0   \n",
       "2795        2795  100889  164.75961    80.0                   0  74.0   \n",
       "2796        2796  100008  164.75961    80.0                   0  37.0   \n",
       "\n",
       "      blood_sugar_d1_min  blood_sugar_d1_max  blood_sugar_d3_min  \\\n",
       "0               4.660000            4.660000            4.925083   \n",
       "1               5.300000            5.300000            3.902008   \n",
       "2               5.190000            5.190000            5.538094   \n",
       "3               4.939551            4.895466            4.694930   \n",
       "4               5.793085            6.349398            5.576803   \n",
       "...                  ...                 ...                 ...   \n",
       "2792            4.340000            4.340000            5.230405   \n",
       "2793            4.091314            7.067830            4.062333   \n",
       "2794            4.330000            4.330000            5.489082   \n",
       "2795            4.040000            4.040000            4.339569   \n",
       "2796            5.499901            5.495763            5.074219   \n",
       "\n",
       "      blood_sugar_d3_max  ...  AlbumintoGlobulinRatio   Male  Consciousness  \\\n",
       "0               5.956664  ...                1.382490  False            1.0   \n",
       "1               4.507097  ...                1.129046  False            1.0   \n",
       "2               7.640623  ...                1.367413   True            1.0   \n",
       "3               4.862858  ...                1.125873  False            1.0   \n",
       "4               5.064091  ...                1.006937   True            1.0   \n",
       "...                  ...  ...                     ...    ...            ...   \n",
       "2792            3.933495  ...                1.560000   True            0.0   \n",
       "2793            4.329303  ...                1.263107   True            1.0   \n",
       "2794            5.853361  ...                1.460000   True            1.0   \n",
       "2795            4.426759  ...                1.150000   True            1.0   \n",
       "2796            6.228706  ...                1.464453   True            1.0   \n",
       "\n",
       "      Temperature  Respiratoryrate  Redcelldistributionwidth  SystolicBP  \\\n",
       "0            36.6             20.0                      12.1  134.500000   \n",
       "1            36.3             23.0                      13.6  135.000000   \n",
       "2            36.6             19.0                      13.4  129.000000   \n",
       "3            36.6             22.0                      12.5  122.000000   \n",
       "4            37.5             24.0                      11.9  122.500000   \n",
       "...           ...              ...                       ...         ...   \n",
       "2792         36.8             24.0                      12.2  100.326822   \n",
       "2793         36.8             22.0                      11.4  101.593761   \n",
       "2794         36.5             26.0                      13.1  124.000000   \n",
       "2795         36.5             26.0                      12.5  139.500000   \n",
       "2796         36.3             24.0                      11.9  117.223687   \n",
       "\n",
       "      DiastolicBP  Lymphocyte(%)  disch_4  \n",
       "0       68.500000      23.384615        3  \n",
       "1       80.000000      32.424242        3  \n",
       "2       91.000000      32.266155        3  \n",
       "3       74.500000      25.101747        3  \n",
       "4       80.000000      15.538462        3  \n",
       "...           ...            ...      ...  \n",
       "2792    66.389026      32.307692        3  \n",
       "2793    78.039515      18.589744        3  \n",
       "2794    76.000000      37.792496        3  \n",
       "2795   100.500000      14.313725        3  \n",
       "2796    67.975513      27.307692        3  \n",
       "\n",
       "[2797 rows x 52 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting based on chapter codes clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2126\n",
       "0     285\n",
       "2     210\n",
       "1     176\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_and_labels = orig_data_and_labels.rename(columns={'disch_4':'cluster'})\n",
    "orig_data_and_labels.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the largest cluster - this is the non-severe cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_remove = 1\n",
    "# Remove the largest n clusters to focus on interesting ones \n",
    "\n",
    "value_counts = orig_data_and_labels.cluster.value_counts()\n",
    "value_counts_list = value_counts.index.to_list()\n",
    "interesting_clusters = value_counts_list[num_to_remove:len(value_counts)]\n",
    "\n",
    "data_and_labels = orig_data_and_labels.loc[orig_data_and_labels['cluster'].isin(interesting_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    285\n",
       "2    210\n",
       "1    176\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_labels.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_all_X, chapters_all_y = preprocess(data_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the class names\n",
    "class_names = [0,2,1]\n",
    "\n",
    "#need to do gridsearch with new rebalanced samples \n",
    "# clf = grid_search_rand_forest(chapters_all_X, chapters_all_y, class_names, downsampling=True, upsampling=True, down_prop=1, up_prop=0.8)\n",
    "\n",
    "#4 clusters\n",
    "clf = ensemble.RandomForestClassifier(criterion='entropy', max_depth=10, max_features='log2',\n",
    "                       n_estimators=30)\n",
    "#3 clusters\n",
    "# clf = ensemble.RandomForestClassifier(n_estimators=80, max_depth=None, max_features='sqrt', \n",
    "#                                       min_samples_split=5, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.52        95\n",
      "           1       0.37      0.27      0.31        59\n",
      "           2       0.49      0.51      0.50        70\n",
      "\n",
      "    accuracy                           0.47       224\n",
      "   macro avg       0.45      0.45      0.45       224\n",
      "weighted avg       0.46      0.47      0.46       224\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.47      0.45        95\n",
      "           1       0.38      0.31      0.34        59\n",
      "           2       0.36      0.37      0.37        70\n",
      "\n",
      "    accuracy                           0.40       224\n",
      "   macro avg       0.39      0.38      0.38       224\n",
      "weighted avg       0.40      0.40      0.39       224\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.55      0.51        95\n",
      "           1       0.31      0.24      0.27        58\n",
      "           2       0.43      0.43      0.43        70\n",
      "\n",
      "    accuracy                           0.43       223\n",
      "   macro avg       0.41      0.41      0.40       223\n",
      "weighted avg       0.42      0.43      0.42       223\n",
      "\n",
      "overall average performance:\n",
      "accuracy:  0.4321882340380099\n",
      "true positive rate/recall:  0.41232039772136364\n",
      "precision:  0.41618533014885634\n",
      "f measure:  0.4118542568030548\n"
     ]
    }
   ],
   "source": [
    "# class_names = orig_data_and_labels['cluster'].unique()\n",
    "X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(chapters_all_X, chapters_all_y, class_names, downsampling = False, upsampling=True, down_prop=1, up_prop=0.8, clf=clf, printing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of stage 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this is the data including imputed values for test results etc \n",
    "all_data = pd.read_csv('imputed_all_data.csv')\n",
    "parse_dates=['admission_date_structured']\n",
    "# labels = pd.read_csv('chapter_codes_clusters3.csv')\n",
    "combined_clean = pd.read_csv('combined_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclusters = subclusters.rename(columns={'disch_4_sub_clusters':'cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>disch_3</th>\n",
       "      <th>disch_3_sub_clusters</th>\n",
       "      <th>disch_4</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100251</td>\n",
       "      <td>1</td>\n",
       "      <td>1b</td>\n",
       "      <td>3</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101019</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102696</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101588</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100358</td>\n",
       "      <td>1</td>\n",
       "      <td>1b</td>\n",
       "      <td>3</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>2792</td>\n",
       "      <td>101460</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>100047</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>103038</td>\n",
       "      <td>1</td>\n",
       "      <td>1b</td>\n",
       "      <td>3</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>100889</td>\n",
       "      <td>1</td>\n",
       "      <td>1d</td>\n",
       "      <td>3</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>100008</td>\n",
       "      <td>1</td>\n",
       "      <td>1b</td>\n",
       "      <td>3</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id  disch_3 disch_3_sub_clusters  disch_4 cluster\n",
       "0              0  100251        1                   1b        3      3a\n",
       "1              1  101019        1                   1d        3      3b\n",
       "2              2  102696        1                   1d        3      3b\n",
       "3              3  101588        1                   1d        3      3b\n",
       "4              4  100358        1                   1b        3      3a\n",
       "...          ...     ...      ...                  ...      ...     ...\n",
       "2792        2792  101460        1                   1d        3      3b\n",
       "2793        2793  100047        1                   1d        3      3b\n",
       "2794        2794  103038        1                   1b        3      3a\n",
       "2795        2795  100889        1                   1d        3      3b\n",
       "2796        2796  100008        1                   1b        3      3a\n",
       "\n",
       "[2797 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_and_labels = pd.merge(all_data, subclusters[['id','cluster']],\n",
    "                           how='right', on='id')\n",
    "# orig_data_and_labels = pd.merge(all_data, sublabels_0,\n",
    "#                            how='right', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comorbidities \n",
    "orig_data_and_labels = orig_data_and_labels.drop(columns=['morbidity_Diabetes','morbidity_COPD',\n",
    "                                                                 'morbidity_Hypertension','morbidity_Heartdisease',\n",
    "                                                                 'morbidity_Renaldisease','morbidity_Tumor',\n",
    "                                                                 'morbidity_Metabolicdisorders',\n",
    "                                                                 'morbidity_Respiratorydiseases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>smoking_structured</th>\n",
       "      <th>age</th>\n",
       "      <th>blood_sugar_d1_min</th>\n",
       "      <th>blood_sugar_d1_max</th>\n",
       "      <th>blood_sugar_d3_min</th>\n",
       "      <th>blood_sugar_d3_max</th>\n",
       "      <th>...</th>\n",
       "      <th>AlbumintoGlobulinRatio</th>\n",
       "      <th>Male</th>\n",
       "      <th>Consciousness</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Respiratoryrate</th>\n",
       "      <th>Redcelldistributionwidth</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>Lymphocyte(%)</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100251</td>\n",
       "      <td>155.00000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.925083</td>\n",
       "      <td>5.956664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.382490</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>23.384615</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101019</td>\n",
       "      <td>151.00000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>3.902008</td>\n",
       "      <td>4.507097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129046</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.424242</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102696</td>\n",
       "      <td>169.00000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>5.538094</td>\n",
       "      <td>7.640623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367413</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>32.266155</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101588</td>\n",
       "      <td>161.00000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.939551</td>\n",
       "      <td>4.895466</td>\n",
       "      <td>4.694930</td>\n",
       "      <td>4.862858</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125873</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>25.101747</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100358</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.793085</td>\n",
       "      <td>6.349398</td>\n",
       "      <td>5.576803</td>\n",
       "      <td>5.064091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006937</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15.538462</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>2792</td>\n",
       "      <td>101460</td>\n",
       "      <td>172.00000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>5.230405</td>\n",
       "      <td>3.933495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>100.326822</td>\n",
       "      <td>66.389026</td>\n",
       "      <td>32.307692</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>100047</td>\n",
       "      <td>172.00000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.091314</td>\n",
       "      <td>7.067830</td>\n",
       "      <td>4.062333</td>\n",
       "      <td>4.329303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263107</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>101.593761</td>\n",
       "      <td>78.039515</td>\n",
       "      <td>18.589744</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>103038</td>\n",
       "      <td>174.00000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>5.489082</td>\n",
       "      <td>5.853361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>37.792496</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>100889</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.339569</td>\n",
       "      <td>4.426759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>14.313725</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>100008</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.499901</td>\n",
       "      <td>5.495763</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>6.228706</td>\n",
       "      <td>...</td>\n",
       "      <td>1.464453</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>117.223687</td>\n",
       "      <td>67.975513</td>\n",
       "      <td>27.307692</td>\n",
       "      <td>3a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id     Height  Weight  smoking_structured   age  \\\n",
       "0              0  100251  155.00000    60.0                   0  62.0   \n",
       "1              1  101019  151.00000    63.0                   0  72.0   \n",
       "2              2  102696  169.00000    80.0                   0  63.0   \n",
       "3              3  101588  161.00000    57.0                   0  39.0   \n",
       "4              4  100358  164.75961    65.0                   0  62.0   \n",
       "...          ...     ...        ...     ...                 ...   ...   \n",
       "2792        2792  101460  172.00000    72.0                   0  49.0   \n",
       "2793        2793  100047  172.00000    75.0                   0  45.0   \n",
       "2794        2794  103038  174.00000    72.0                   0  56.0   \n",
       "2795        2795  100889  164.75961    80.0                   0  74.0   \n",
       "2796        2796  100008  164.75961    80.0                   0  37.0   \n",
       "\n",
       "      blood_sugar_d1_min  blood_sugar_d1_max  blood_sugar_d3_min  \\\n",
       "0               4.660000            4.660000            4.925083   \n",
       "1               5.300000            5.300000            3.902008   \n",
       "2               5.190000            5.190000            5.538094   \n",
       "3               4.939551            4.895466            4.694930   \n",
       "4               5.793085            6.349398            5.576803   \n",
       "...                  ...                 ...                 ...   \n",
       "2792            4.340000            4.340000            5.230405   \n",
       "2793            4.091314            7.067830            4.062333   \n",
       "2794            4.330000            4.330000            5.489082   \n",
       "2795            4.040000            4.040000            4.339569   \n",
       "2796            5.499901            5.495763            5.074219   \n",
       "\n",
       "      blood_sugar_d3_max  ...  AlbumintoGlobulinRatio   Male  Consciousness  \\\n",
       "0               5.956664  ...                1.382490  False            1.0   \n",
       "1               4.507097  ...                1.129046  False            1.0   \n",
       "2               7.640623  ...                1.367413   True            1.0   \n",
       "3               4.862858  ...                1.125873  False            1.0   \n",
       "4               5.064091  ...                1.006937   True            1.0   \n",
       "...                  ...  ...                     ...    ...            ...   \n",
       "2792            3.933495  ...                1.560000   True            0.0   \n",
       "2793            4.329303  ...                1.263107   True            1.0   \n",
       "2794            5.853361  ...                1.460000   True            1.0   \n",
       "2795            4.426759  ...                1.150000   True            1.0   \n",
       "2796            6.228706  ...                1.464453   True            1.0   \n",
       "\n",
       "      Temperature  Respiratoryrate  Redcelldistributionwidth  SystolicBP  \\\n",
       "0            36.6             20.0                      12.1  134.500000   \n",
       "1            36.3             23.0                      13.6  135.000000   \n",
       "2            36.6             19.0                      13.4  129.000000   \n",
       "3            36.6             22.0                      12.5  122.000000   \n",
       "4            37.5             24.0                      11.9  122.500000   \n",
       "...           ...              ...                       ...         ...   \n",
       "2792         36.8             24.0                      12.2  100.326822   \n",
       "2793         36.8             22.0                      11.4  101.593761   \n",
       "2794         36.5             26.0                      13.1  124.000000   \n",
       "2795         36.5             26.0                      12.5  139.500000   \n",
       "2796         36.3             24.0                      11.9  117.223687   \n",
       "\n",
       "      DiastolicBP  Lymphocyte(%)  cluster  \n",
       "0       68.500000      23.384615       3a  \n",
       "1       80.000000      32.424242       3b  \n",
       "2       91.000000      32.266155       3b  \n",
       "3       74.500000      25.101747       3b  \n",
       "4       80.000000      15.538462       3a  \n",
       "...           ...            ...      ...  \n",
       "2792    66.389026      32.307692       3b  \n",
       "2793    78.039515      18.589744       3b  \n",
       "2794    76.000000      37.792496       3a  \n",
       "2795   100.500000      14.313725       3b  \n",
       "2796    67.975513      27.307692       3a  \n",
       "\n",
       "[2797 rows x 52 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3b    1281\n",
       "3a     845\n",
       "0a     150\n",
       "1b     131\n",
       "2b     120\n",
       "0c     113\n",
       "2a      90\n",
       "1a      45\n",
       "0b      22\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_and_labels.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_remove = 2\n",
    "# Remove the largest n clusters to focus on interesting ones \n",
    "\n",
    "value_counts = orig_data_and_labels.cluster.value_counts()\n",
    "value_counts_list = value_counts.index.to_list()\n",
    "interesting_clusters = value_counts_list[num_to_remove:len(value_counts)]\n",
    "\n",
    "data_and_labels = orig_data_and_labels.loc[orig_data_and_labels['cluster'].isin(interesting_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0a    150\n",
       "1b    131\n",
       "2b    120\n",
       "0c    113\n",
       "2a     90\n",
       "1a     45\n",
       "0b     22\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_labels.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new dataframe for each cluster, so we have separate classification problems \n",
    "\n",
    "0b/1a is most severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0a = data_and_labels[data_and_labels.cluster == '0a']\n",
    "c0b = data_and_labels[data_and_labels.cluster == '0b']\n",
    "c0c = data_and_labels[data_and_labels.cluster == '0c']\n",
    "c0 = pd.concat([c0a,c0b]).drop(columns={'Unnamed: 0'})\n",
    "c0 = pd.concat([c0,c0c]).drop(columns={'Unnamed: 0'})\n",
    "\n",
    "c1a = data_and_labels[data_and_labels.cluster == '1a']\n",
    "c1b = data_and_labels[data_and_labels.cluster == '1b']\n",
    "c1 = pd.concat([c1a,c1b]).drop(columns={'Unnamed: 0'})\n",
    "\n",
    "c2a = data_and_labels[data_and_labels.cluster == '2a']\n",
    "c2b = data_and_labels[data_and_labels.cluster == '2b']\n",
    "c2 = pd.concat([c2a,c2b]).drop(columns={'Unnamed: 0'})\n",
    "\n",
    "cSevere = pd.concat([c0b,c1a]).drop(columns={'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "subchapters_all_X0, subchapters_all_y0 = preprocess(c0)\n",
    "subchapters_all_X1, subchapters_all_y1 = preprocess(c1)\n",
    "subchapters_all_X2, subchapters_all_y2 = preprocess(c2)\n",
    "subchapters_all_XSevere, subchapters_all_ySevere = preprocess(cSevere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names=subchapters_all_y0.cluster.unique()\n",
    "# clf0 = grid_search_rand_forest(subchapters_all_X0, subchapters_all_y0,class_names, downsampling=False, upsampling=True, down_prop=1, up_prop=0.8)\n",
    "# clf0 = ensemble.RandomForestClassifier(max_features='sqrt', min_samples_split=10,\n",
    "#                        n_estimators=20)\n",
    "\n",
    "# class_names=subchapters_all_y1.cluster.unique()\n",
    "# clf1 = grid_search_rand_forest(subchapters_all_X1, subchapters_all_y1,class_names, downsampling=False, upsampling=True, down_prop=1, up_prop=0.8)\n",
    "# clf1 = ensemble.RandomForestClassifier(max_depth=5, max_features='sqrt', min_samples_split=10,\n",
    "#                        n_estimators=20)\n",
    "\n",
    "# class_names=subchapters_all_y2.cluster.unique()\n",
    "# clf2 = grid_search_rand_forest(subchapters_all_X2, subchapters_all_y2,class_names, downsampling=False, upsampling=True, down_prop=1, up_prop=0.8)\n",
    "# clf2 = ensemble.RandomForestClassifier(max_features='log2', n_estimators=15)\n",
    "\n",
    "class_names=subchapters_all_ySevere.cluster.unique()\n",
    "# clfSevere = grid_search_rand_forest(subchapters_all_XSevere, subchapters_all_ySevere,class_names, downsampling=False, upsampling=True, down_prop=1, up_prop=0.8)\n",
    "clfSevere = ensemble.RandomForestClassifier(criterion='entropy', max_depth=10, max_features='sqrt',\n",
    "                       min_samples_split=5, n_estimators=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validating...\n",
      "value counts:  1a    30\n",
      "0b    14\n",
      "Name: cluster, dtype: int64\n",
      "value counts: 1a    30\n",
      "0b    26\n",
      "Name: cluster, dtype: int64\n",
      "(array(['0b', '1a'], dtype=object), array([10, 13]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0b       0.30      0.38      0.33         8\n",
      "          1a       0.62      0.53      0.57        15\n",
      "\n",
      "    accuracy                           0.48        23\n",
      "   macro avg       0.46      0.45      0.45        23\n",
      "weighted avg       0.51      0.48      0.49        23\n",
      "\n",
      "accuracy:  0.4782608695652174\n",
      "true positive rate / recall:  0.45416666666666666\n",
      "precision:  0.45769230769230773\n",
      "f measure:  0.4523809523809524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "value counts:  1a    30\n",
      "0b    15\n",
      "Name: cluster, dtype: int64\n",
      "value counts: 1a    30\n",
      "0b    27\n",
      "Name: cluster, dtype: int64\n",
      "(array(['0b', '1a'], dtype=object), array([ 8, 14]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0b       0.38      0.43      0.40         7\n",
      "          1a       0.71      0.67      0.69        15\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.54      0.55      0.54        22\n",
      "weighted avg       0.61      0.59      0.60        22\n",
      "\n",
      "accuracy:  0.5909090909090909\n",
      "true positive rate / recall:  0.5476190476190476\n",
      "precision:  0.5446428571428572\n",
      "f measure:  0.5448275862068965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "value counts:  1a    30\n",
      "0b    15\n",
      "Name: cluster, dtype: int64\n",
      "value counts: 1a    30\n",
      "0b    27\n",
      "Name: cluster, dtype: int64\n",
      "(array(['0b', '1a'], dtype=object), array([10, 12]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0b       0.30      0.43      0.35         7\n",
      "          1a       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.48      0.48      0.47        22\n",
      "weighted avg       0.55      0.50      0.52        22\n",
      "\n",
      "accuracy:  0.5\n",
      "true positive rate / recall:  0.4809523809523809\n",
      "precision:  0.4833333333333333\n",
      "f measure:  0.4727668845315904\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "overall average performance:\n",
      "accuracy:  0.5230566534914362\n",
      "true positive rate/recall:  0.4942460317460317\n",
      "precision:  0.4952228327228328\n",
      "f measure:  0.48999180770647977\n"
     ]
    }
   ],
   "source": [
    "# class_names = subchapters_all_y0['cluster'].unique()\n",
    "# X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(subchapters_all_X0, subchapters_all_y0, class_names, \n",
    "#                                                            downsampling = True, upsampling=True,\n",
    "#                                                            down_prop = 1, up_prop = 0.8, clf=clf0, printing=False)\n",
    "\n",
    "# class_names = subchapters_all_y1['cluster'].unique()\n",
    "# X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(subchapters_all_X1, subchapters_all_y1, class_names, \n",
    "#                                                            downsampling = True, upsampling=True,\n",
    "#                                                            down_prop = 1, up_prop = 0.8, clf=clf1, printing=False)\n",
    "\n",
    "# class_names = subchapters_all_y2['cluster'].unique()\n",
    "# X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(subchapters_all_X2, subchapters_all_y2, class_names, \n",
    "#                                                            downsampling = True, upsampling=True,\n",
    "#                                                            down_prop = 1, up_prop = 0.8, clf=clf1, printing=False)\n",
    "\n",
    "class_names = subchapters_all_ySevere['cluster'].unique()\n",
    "X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(subchapters_all_XSevere, subchapters_all_ySevere, class_names, \n",
    "                                                           downsampling = True, upsampling=True,\n",
    "                                                           down_prop = 1, up_prop = 0.8, clf=clfSevere, printing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
