{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the data including imputed values for test results etc \n",
    "all_data = pd.read_csv('imputed_all_data.csv')\n",
    "parse_dates=['admission_date_structured']\n",
    "labels = pd.read_csv('new_dbscan_9clus.csv')\n",
    "combined_clean = pd.read_csv('combined_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comorbidities \n",
    "orig_data_and_labels = orig_data_and_labels_comorb.drop(columns=['Unnamed: 0','morbidity_Diabetes','morbidity_COPD','morbidity_Hypertension','morbidity_Heartdisease','morbidity_Renaldisease','morbidity_Tumor','morbidity_Metabolicdisorders','morbidity_Respiratorydiseases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>smoking_structured</th>\n",
       "      <th>age</th>\n",
       "      <th>blood_sugar_d1_min</th>\n",
       "      <th>blood_sugar_d1_max</th>\n",
       "      <th>blood_sugar_d3_min</th>\n",
       "      <th>blood_sugar_d3_max</th>\n",
       "      <th>SystolicBP_d1_min</th>\n",
       "      <th>...</th>\n",
       "      <th>AlbumintoGlobulinRatio</th>\n",
       "      <th>Male</th>\n",
       "      <th>Consciousness</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Respiratoryrate</th>\n",
       "      <th>Redcelldistributionwidth</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>Lymphocyte(%)</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100251</td>\n",
       "      <td>155.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.925083</td>\n",
       "      <td>5.956664</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.382490</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>23.384615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100358</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.793085</td>\n",
       "      <td>6.349398</td>\n",
       "      <td>5.576803</td>\n",
       "      <td>5.064091</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006937</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15.538462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101536</td>\n",
       "      <td>158.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.248720</td>\n",
       "      <td>6.629004</td>\n",
       "      <td>4.899923</td>\n",
       "      <td>5.805336</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437422</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>46.326531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101289</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.458859</td>\n",
       "      <td>5.799471</td>\n",
       "      <td>3.930688</td>\n",
       "      <td>4.154902</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.329695</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>22.432432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100851</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>4.348679</td>\n",
       "      <td>5.624614</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283246</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>27.342448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>102301</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>5.335332</td>\n",
       "      <td>5.082172</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>20.384615</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>101680</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.029389</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>102631</td>\n",
       "      <td>168.00000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>8.358209</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>100166</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.029389</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.133798</td>\n",
       "      <td>7.149667</td>\n",
       "      <td>11.590000</td>\n",
       "      <td>11.590000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>100181</td>\n",
       "      <td>164.75961</td>\n",
       "      <td>65.029389</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.028059</td>\n",
       "      <td>6.916851</td>\n",
       "      <td>5.744956</td>\n",
       "      <td>5.496064</td>\n",
       "      <td>99.634251</td>\n",
       "      <td>...</td>\n",
       "      <td>1.443721</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.225441</td>\n",
       "      <td>111.273004</td>\n",
       "      <td>69.780542</td>\n",
       "      <td>33.269486</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2760 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     Height     Weight  smoking_structured   age  \\\n",
       "0     100251  155.00000  60.000000                   0  62.0   \n",
       "1     100358  164.75961  65.000000                   0  62.0   \n",
       "2     101536  158.00000  50.000000                   0  48.0   \n",
       "3     101289  165.00000  60.000000                   0  50.0   \n",
       "4     100851  170.00000  70.000000                   0  74.0   \n",
       "...      ...        ...        ...                 ...   ...   \n",
       "2755  102301  175.00000  72.000000                   0  67.0   \n",
       "2756  101680  164.75961  65.029389                   1  77.0   \n",
       "2757  102631  168.00000  65.000000                   0  75.0   \n",
       "2758  100166  164.75961  65.029389                   0  69.0   \n",
       "2759  100181  164.75961  65.029389                   0  75.0   \n",
       "\n",
       "      blood_sugar_d1_min  blood_sugar_d1_max  blood_sugar_d3_min  \\\n",
       "0               4.660000            4.660000            4.925083   \n",
       "1               5.793085            6.349398            5.576803   \n",
       "2               5.248720            6.629004            4.899923   \n",
       "3               4.458859            5.799471            3.930688   \n",
       "4               5.270000            5.270000            4.348679   \n",
       "...                  ...                 ...                 ...   \n",
       "2755            4.110000            4.110000            5.335332   \n",
       "2756            5.680000            5.680000            6.280000   \n",
       "2757            8.380000            8.380000            6.140000   \n",
       "2758            4.133798            7.149667           11.590000   \n",
       "2759            4.028059            6.916851            5.744956   \n",
       "\n",
       "      blood_sugar_d3_max  SystolicBP_d1_min  ...  AlbumintoGlobulinRatio  \\\n",
       "0               5.956664         124.000000  ...                1.382490   \n",
       "1               5.064091         115.000000  ...                1.006937   \n",
       "2               5.805336          98.000000  ...                1.437422   \n",
       "3               4.154902         118.000000  ...                1.329695   \n",
       "4               5.624614         116.000000  ...                1.283246   \n",
       "...                  ...                ...  ...                     ...   \n",
       "2755            5.082172         114.000000  ...                1.240000   \n",
       "2756            6.280000          98.000000  ...                1.240000   \n",
       "2757            6.140000         130.000000  ...                1.700000   \n",
       "2758           11.590000         121.000000  ...                1.120000   \n",
       "2759            5.496064          99.634251  ...                1.443721   \n",
       "\n",
       "       Male  Consciousness  Temperature  Respiratoryrate  \\\n",
       "0     False            1.0         36.6             20.0   \n",
       "1      True            1.0         37.5             24.0   \n",
       "2     False            1.0         36.7             22.0   \n",
       "3     False            1.0         36.5             20.0   \n",
       "4      True            1.0         36.8             24.0   \n",
       "...     ...            ...          ...              ...   \n",
       "2755   True            1.0         36.5             28.0   \n",
       "2756   True            0.0         37.2             18.0   \n",
       "2757   True            1.0         36.3             23.0   \n",
       "2758   True            1.0         38.2             23.0   \n",
       "2759   True            1.0         37.4             22.0   \n",
       "\n",
       "      Redcelldistributionwidth  SystolicBP  DiastolicBP  Lymphocyte(%)  \\\n",
       "0                    12.100000  134.500000    68.500000      23.384615   \n",
       "1                    11.900000  122.500000    80.000000      15.538462   \n",
       "2                    11.300000  108.000000    62.500000      46.326531   \n",
       "3                    13.600000  122.000000    73.000000      22.432432   \n",
       "4                    12.700000  121.500000    81.000000      27.342448   \n",
       "...                        ...         ...          ...            ...   \n",
       "2755                 14.600000  120.000000    74.500000      20.384615   \n",
       "2756                 16.400000  118.500000    63.500000       5.454545   \n",
       "2757                 12.500000  140.000000    70.000000       8.358209   \n",
       "2758                 11.700000  134.000000    83.000000      33.750000   \n",
       "2759                 14.225441  111.273004    69.780542      33.269486   \n",
       "\n",
       "      cluster  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "2755        8  \n",
       "2756        8  \n",
       "2757        8  \n",
       "2758        8  \n",
       "2759        8  \n",
       "\n",
       "[2760 rows x 51 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting binary severity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we redefine the clusters into 2 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 6_kmodes\n",
    "limited_clusters = True\n",
    "if(limited_clusters):\n",
    "    data_and_labels = orig_data_and_labels.copy()\n",
    "    #group clusters together into non-severe, medium, severe\n",
    "    data_and_labels['cluster'] = orig_data_and_labels['cluster'].apply(\n",
    "        lambda x: 'remainder' if (x==0 or x==1 or x==2 or x==3 or x==4 or x==6 or x==5 or x==8) else x)\n",
    "#     data_and_labels['cluster'] = data_and_labels['cluster'].apply(\n",
    "#         lambda x: 'medium' if (x==0) else x)    \n",
    "    data_and_labels['cluster'] = data_and_labels['cluster'].apply(\n",
    "        lambda x: 'seven' if (x==7) else x)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remainder    2732\n",
       "seven          28\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_labels.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "five = data_and_labels[data_and_labels.cluster=='five']\n",
    "remainder = data_and_labels[data_and_labels.cluster=='remainder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "def preprocess(all_data):\n",
    "#     Split the dataset into features and labels (clusters) - so we can normalise the features but not the labels\n",
    "    all_X = all_data.iloc[:,2:len(all_data.columns)-1]\n",
    "    all_y = all_data['cluster']\n",
    "    \n",
    "    # normalise the data so we have unit variance and mean 0 using built-in preprocessing method in sklearn\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    all_X= pd.DataFrame(scaler.fit_transform(all_X),columns=all_X.columns)\n",
    "    \n",
    "#     reset the indexes otherwise it was breaking\n",
    "    all_X= all_X.reset_index()\n",
    "    all_y = all_y.reset_index()\n",
    "    all_X = all_X.drop(columns=['index'])\n",
    "    all_y = all_y.drop(columns=['index'])\n",
    "    \n",
    "    #prepare data for training a model by splitting into training and testing data \n",
    "    return (all_X, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X, all_y = preprocess(data_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the class names\n",
    "class_names = ['seven','remainder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up performance metrics calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#method to compute performance metrics \n",
    "def performance_metrics(y_true, y_pred):\n",
    "    #create a confusion matrix from results \n",
    "    cnf_matrix  = metrics.confusion_matrix(y_true, y_pred, labels=class_names, sample_weight=None)\n",
    "#     # average over all classes to find overall fp,fn,tp,tn\n",
    "#     FP = np.sum(cnf_matrix, axis=0) - np.diag(cnf_matrix)\n",
    "#     FN = np.sum(cnf_matrix, axis=1) - np.diag(cnf_matrix)\n",
    "#     TP = np.diag(cnf_matrix)\n",
    "#     TN = np.sum(cnf_matrix) - (FP + FN + TP)\n",
    "        \n",
    "    #find out if each predicted label is right \n",
    "    correct_labels = 0\n",
    "    for i, true_label in enumerate(y_true):\n",
    "        if (true_label == y_pred[i]):\n",
    "            correct_labels += 1\n",
    "\n",
    "    #calculate overall accuracy\n",
    "#     acc = np.round(correct_labels/y_pred.shape[0],2)\n",
    "        \n",
    "    # tp rate is the same as recall \n",
    "#     recall = np.sum(TP)/(np.sum(TP)+np.sum(FN))\n",
    "#     FP_rate = np.sum(FP)/(np.sum(FP)+np.sum(TN))  \n",
    "#     precision = np.sum(TP)/(np.sum(TP)+np.sum(FP)) \n",
    "#     f_measure = (2*precision*recall)/(precision + recall) \n",
    "\n",
    "    metrics_dict = metrics.classification_report(y_true,y_pred,output_dict=True)\n",
    "    avg_metrics = metrics_dict['macro avg']\n",
    "    \n",
    "    recall = avg_metrics['recall']\n",
    "    precision = avg_metrics['precision']\n",
    "    f_measure = avg_metrics['f1-score']\n",
    "    acc = metrics_dict['accuracy']\n",
    "    \n",
    "    print(metrics.classification_report(y_true,y_pred))\n",
    "    \n",
    "    return (acc, recall, precision, f_measure,\n",
    "            np.round(cnf_matrix/cnf_matrix.sum(axis=1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "#method to plot the confusion matrix \n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix, index = [i for i in class_names], columns = [i for i in class_names])\n",
    "    plt.figure()\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use k-fold cross validation to evaluate the effectiveness of our models, where each 'fold' results in a slightly different train/test split, allowing us to see how the model beaves with different data. We can compute various metrics about the model performance, and from these results, we can choose the most effective classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "\n",
    "def cross_val(all_X, all_y, class_names, downsampling, upsampling, down_prop, up_prop, clf, printing):\n",
    "    print('cross-validating...')\n",
    "    k_val = 3\n",
    "    #use 3 splits \n",
    "    k_fold = model_selection.KFold(n_splits=k_val)\n",
    "    strat_k_fold = model_selection.StratifiedKFold(n_splits=k_val, shuffle=True)\n",
    "\n",
    "    #create empty arrays to store the results from each fold\n",
    "    #we can then average these to get the overall classifications and performance \n",
    "    accuracies = np.empty(k_val)\n",
    "    tp_rates = np.empty(k_val)\n",
    "    precisions = np.empty(k_val)\n",
    "    f_measures = np.empty(k_val)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    #split training data into training and validation sets\n",
    "    for train_indices, validation_indices in strat_k_fold.split(all_X, all_y):\n",
    "    #     print(X_train.index)\n",
    "        X_training = all_X.iloc[train_indices]\n",
    "        y_training = all_y.iloc[train_indices]\n",
    "        X_validate = all_X.iloc[validation_indices]\n",
    "        y_validate = all_y.iloc[validation_indices]\n",
    "        \n",
    "        # upsample the training data in each fold, if upsample = true\n",
    "        #with stratified k fold, better not to upsample, as it preserves percentage of samples for each class \n",
    "#         print('value counts: ', y_training.value_counts())\n",
    "\n",
    "        if(downsampling):\n",
    "#             print('downsampling...')\n",
    "            X_training, y_training = downsample(X_training, y_training, class_names, down_prop)\n",
    "            if (printing):\n",
    "                print('value counts: ', y_training.value_counts())\n",
    "\n",
    "        if (upsampling):\n",
    "#             print('upsampling...')\n",
    "            X_training, y_training = upsample(X_training, y_training, class_names, up_prop)\n",
    "            if (printing):\n",
    "                print('value counts:', y_training.value_counts())\n",
    "            \n",
    "        # fit classifier\n",
    "        clf.fit(X_training, y_training.values.ravel())\n",
    "        \n",
    "        #predict \n",
    "        y_predicted = clf.predict(X_validate)\n",
    "        y_true_val = y_validate.cluster\n",
    "        \n",
    "        #if we are using the decision tree classifier we may want to export the tree to look at it \n",
    "        from sklearn import tree\n",
    "\n",
    "        export_tree = False\n",
    "        if(export_tree):\n",
    "            for tree_in_forest in clf.estimators_:\n",
    "                if(export_tree):\n",
    "                    tree.export_graphviz(tree_in_forest, out_file=\"rotated_tree_eg.dot\",filled = True, \n",
    "                                         feature_names = X_training.columns, class_names=class_names,\n",
    "                                         rotate = True)\n",
    "        if (printing):\n",
    "            print(np.unique(y_predicted, return_counts=True))\n",
    "\n",
    "        #see how validation set performs \n",
    "        acc, recall, precision, f_measure, confusion_matrix = performance_metrics(y_true_val.values, y_predicted)\n",
    "\n",
    "        if (printing):\n",
    "            #print performance results for each fold\n",
    "            print(\"accuracy: \", acc)\n",
    "            print(\"true positive rate / recall: \", recall)\n",
    "            print(\"precision: \", precision)\n",
    "            print(\"f measure: \", f_measure)\n",
    "            plot_confusion_matrix(confusion_matrix, class_names)\n",
    "            print(\"----------\")\n",
    "\n",
    "        # store info for each fold \n",
    "        accuracies[count] = acc\n",
    "        tp_rates[count] = recall\n",
    "        precisions[count] = precision\n",
    "        f_measures[count] = f_measure\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    #average scores\n",
    "    cv_acc = np.mean(accuracies)\n",
    "    cv_tp = np.mean(tp_rates)\n",
    "    cv_precision = np.mean(precisions)\n",
    "    cv_f_measure = np.mean(f_measures)\n",
    "\n",
    "\n",
    "    print(\"overall average performance:\")\n",
    "    print(\"accuracy: \", cv_acc)\n",
    "    print(\"true positive rate/recall: \", cv_tp)\n",
    "    print(\"precision: \", cv_precision)\n",
    "    print(\"f measure: \", cv_f_measure)\n",
    "    \n",
    "    return X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to perform grid search to find the best parameters for the random forest classifier, uses cross-val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to implement this manually due to library constraints and difficulties with upsampling properly inside gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, pipeline, ensemble\n",
    "\n",
    "def grid_search_rand_forest(data_X, data_y,class_names, downsampling, upsampling, down_prop, up_prop):\n",
    "\n",
    "    best_f = 0.0\n",
    "    \n",
    "    # gridsearch for parameter optimisation\n",
    "    param_grid = { \n",
    "        'n_estimators': [5, 10, 15, 20, 30, 40, 60, 80],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'criterion' :['gini', 'entropy']}\n",
    "    \n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for max_features in param_grid['max_features']:\n",
    "                for min_samples_split in param_grid['min_samples_split']:\n",
    "                    for criterion in param_grid['criterion']:\n",
    "                        clf = ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, \n",
    "                                               min_samples_split=min_samples_split, criterion=criterion)\n",
    "\n",
    "                        X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, f_measure = cross_val(data_X, data_y, class_names, downsampling, upsampling, down_prop, up_prop, clf, printing=False)\n",
    "\n",
    "                        if(f_measure > best_f):\n",
    "                            best_f = f_measure\n",
    "                            best_clf = clf\n",
    "    \n",
    "    # Create grid search object\n",
    "#     clf = model_selection.GridSearchCV(estimator=ensemble.RandomForestClassifier(), param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "\n",
    "#     best_clf = clf.fit(data_X, data_y.values.ravel())\n",
    "\n",
    "#     gridsearch_results = pd.DataFrame(best_clf.cv_results_)\n",
    "\n",
    "    #sort according to overall rank score to find best params\n",
    "#     best_params_found = gridsearch_results.sort_values('rank_test_score').iloc[0]\n",
    "    print(best_clf)\n",
    "    \n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address class imbalance by removing some examples in most numerous classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(train_X, train_y, class_names, down_prop):\n",
    "    \n",
    "    train_data_and_labels = train_X.copy()\n",
    "    train_data_and_labels['cluster'] = train_y\n",
    "    \n",
    "    #find the largest class and the number of samples in training\n",
    "    value_counts = train_data_and_labels.cluster.value_counts()\n",
    "    max_val = max(value_counts)\n",
    "\n",
    "    most_numerous =  train_data_and_labels.cluster.value_counts().index[0]\n",
    "    big_cluster = train_data_and_labels[train_data_and_labels['cluster']==most_numerous]\n",
    "    new_train = train_data_and_labels[train_data_and_labels.cluster!=most_numerous]\n",
    "    #remove more individuals in largest class if limited classes, as class imbalance is bigger here\n",
    "    reduced_cluster = big_cluster.sample(replace=False, n=int(len(big_cluster)*down_prop), random_state=1)\n",
    "    train_down = new_train.append(reduced_cluster)\n",
    "    y_train_down = train_down['cluster']\n",
    "    X_train_down = train_down.iloc[:,0:len(train_down.columns)-1]        \n",
    "    \n",
    "    return X_train_down, y_train_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improves the prediction accuracy for the classes containing fewer individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample the least numerous classes\n",
    "def upsample(train_X, train_y, class_names, up_prop):\n",
    "    \n",
    "    train_data_and_labels = train_X.copy()\n",
    "    train_data_and_labels['cluster'] = train_y\n",
    "\n",
    "    #find the largest class and the number of samples in training\n",
    "    value_counts = train_data_and_labels.cluster.value_counts()\n",
    "    max_val = max(value_counts)\n",
    "        \n",
    "    #upsampling all the classes in training data \n",
    "    for cluster in class_names:\n",
    "        cluster_vals = train_data_and_labels[train_data_and_labels.cluster==cluster]\n",
    "        num_in_cluster = len(cluster_vals.index)\n",
    "        num_extra_samples = int(up_prop*(max_val - num_in_cluster))\n",
    "        new_samples = cluster_vals.sample(replace=True, n=num_extra_samples, random_state=1)\n",
    "        train_data_and_labels = train_data_and_labels.append(new_samples)\n",
    "            \n",
    "#     print(train_data_and_labels.cluster.value_counts())\n",
    "    \n",
    "    X_train_up = train_data_and_labels.iloc[:,0:len(train_data_and_labels.columns)-1]\n",
    "    y_train_up = train_data_and_labels['cluster']\n",
    "    \n",
    "    return X_train_up, y_train_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do gridsearch \n",
    "\n",
    "\n",
    "# clf = grid_search_rand_forest(all_X, all_y, class_names, downsampling=True, upsampling=True, down_prop=0.6, up_prop=0.8)\n",
    "\n",
    "#for 5 vs remainder\n",
    "# clf= ensemble.RandomForestClassifier(criterion='entropy', max_depth=10, max_features='sqrt',min_samples_split=5, n_estimators=5)\n",
    "#for 7 vs remainder\n",
    "clf= ensemble.RandomForestClassifier(criterion='entropy', max_depth=5, max_features='sqrt',n_estimators=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the k-fold cross validation on data. Since our dataset is small, the predictions can vary a lot based on which data is used for training/testing, which is why k-fold cross-val is useful to get overall prediction metrics. \n",
    "If upsampling is true then the least numerous classes will be upsampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binaryclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   remainder       0.99      0.99      0.99       911\n",
      "       seven       0.40      0.44      0.42         9\n",
      "\n",
      "    accuracy                           0.99       920\n",
      "   macro avg       0.70      0.72      0.71       920\n",
      "weighted avg       0.99      0.99      0.99       920\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   remainder       0.99      1.00      1.00       911\n",
      "       seven       0.57      0.44      0.50         9\n",
      "\n",
      "    accuracy                           0.99       920\n",
      "   macro avg       0.78      0.72      0.75       920\n",
      "weighted avg       0.99      0.99      0.99       920\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   remainder       0.99      1.00      1.00       910\n",
      "       seven       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.99       920\n",
      "   macro avg       0.78      0.70      0.73       920\n",
      "weighted avg       0.99      0.99      0.99       920\n",
      "\n",
      "overall average performance:\n",
      "accuracy:  0.9898550724637681\n",
      "true positive rate/recall:  0.7126188220041128\n",
      "precision:  0.7542190740985921\n",
      "f measure:  0.7293795579631088\n"
     ]
    }
   ],
   "source": [
    "class_names = ['seven','remainder'] \n",
    "X_training, y_training, X_validate, y_validate, y_predicted, y_true_val, cv_f_measure = cross_val(all_X, all_y, class_names, downsampling=True, upsampling=True, down_prop=0.6, up_prop=0.8, clf=clf, printing=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
