{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "2c. Prognosis Space - DbScan.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQz85GQU17ka"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.spatial.distance import squareform, pdist, euclidean\n",
        "import math \n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install kneed\n",
        "from kneed import KneeLocator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5HmR1v717kj"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O8bmlV17kl"
      },
      "source": [
        "## Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8NcV5xx17km"
      },
      "source": [
        "def reduce_dim(z):\n",
        "    d_0 = 0\n",
        "    d_1 = 0\n",
        "    d_2 = 0\n",
        "    d_3 = 0\n",
        "    los_z = z[-1]\n",
        "    los_windows = {0: list(range(14)), 0.5:list(range(14, 28)), 0.75:list(range(28, 62))}\n",
        "    for k, l in los_windows.items():\n",
        "        if los_z in l:\n",
        "            d_0 = k\n",
        "    \n",
        "    prog_z = z[9:11]\n",
        "    prog_windows = {0:[0,0], 1:[1, 0], 1.5:[0, 1], 1.5:[1, 1]}\n",
        "    for k, l in prog_windows.items():\n",
        "        if (prog_z[0] == l[0]) and (prog_z[1] == l[1]):\n",
        "            d_1 = k\n",
        "    \n",
        "    oxy_z = z[11:-1]\n",
        "    oxy_windows = {0:[0, 0], 0.75:[1, 0], 1:[0, 1], 1.25:[1, 1]}\n",
        "    for k, l in oxy_windows.items():\n",
        "        if (oxy_z[0] == l[0]) and (oxy_z[1] == l[1]):\n",
        "            d_2 = k\n",
        "            if oxy_z[2]:\n",
        "                d_2 += 0.5\n",
        "    \n",
        "    if d_1 + d_2 == 0:\n",
        "        #no other features except los\n",
        "        chap_z = z[:9]\n",
        "        weights = [0.5, 0.5, 0, 0.75, 0, 0, 0, 0.75, 0.5]\n",
        "        d_3 = 0\n",
        "        for c, w in zip(chap_z, weights):\n",
        "            d_3 += c*w\n",
        "    else:\n",
        "        d_3 = 0\n",
        "    \n",
        "    return np.array([d_0, d_1, d_2, d_3])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr7kxG_K17kn"
      },
      "source": [
        "def similarity(x, y):\n",
        "    x_d = reduce_dim(x)\n",
        "    y_d = reduce_dim(y)\n",
        "    return euclidean(x_d, y_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTRD7qXj17kn"
      },
      "source": [
        "def similarity_matrix(data):\n",
        "    sim = pd.DataFrame(squareform(pdist(data, metric = similarity)), columns=data.index, index=data.index)\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY_dHia917kn"
      },
      "source": [
        "## DBScan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrJa06W17ko"
      },
      "source": [
        "def chooseEps(sim, minPts = 10):\n",
        "    neigh = NearestNeighbors(n_neighbors=minPts, n_jobs = -1, metric ='precomputed')\n",
        "    neigh.fit(sim)\n",
        "    dist, ind = neigh.kneighbors(sim)\n",
        "    distances = [dist[i][minPts - 1] for i in range(len(dist))]\n",
        "    plt.scatter(list(range(sim.shape[0])),sorted(distances))\n",
        "    plt.show()\n",
        "    kl = KneeLocator(list(range(sim.shape[0])), distances, curve=\"convex\", direction=\"increasing\")\n",
        "\n",
        "    return kl.knee_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLQBig7G17ko"
      },
      "source": [
        "def tuneEps(sim, rangeEps, minPts = 10):\n",
        "    for i in rangeEps:\n",
        "        print('eps values is ' + str(i))\n",
        "        db = DBSCAN(eps = i, min_samples = minPts, metric = 'precomputed').fit(sim)\n",
        "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "        core_samples_mask[db.core_sample_indices_] = True\n",
        "        labels = db.labels_\n",
        "        n_noise = list(labels).count(-1)\n",
        "        print(set(labels))\n",
        "        print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(sim, labels, metric = 'precomputed'))\n",
        "        print('Estimated number of noise points: %d' % n_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-kh4smr17ko"
      },
      "source": [
        "def plotSilhouette(sim, n_clusters, labels):\n",
        "# based on code from https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(5, 5)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 \n",
        "    ax.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax.set_ylim([0, len(sim) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(sim, labels, metric = 'precomputed')\n",
        "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(sim, labels, metric = 'precomputed')\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                            0, ith_cluster_silhouette_values,\n",
        "                            facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax.set_title((\"Silhouette analysis for DBScan clustering on sample data with n_clusters = %d\" % n_clusters), fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or27q88r17kp"
      },
      "source": [
        "def applyDBScan(sim, eps, minPts = 10):\n",
        "    db = DBSCAN(eps = eps, min_samples = minPts, metric = 'precomputed').fit(sim)\n",
        "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "    core_samples_mask[db.core_sample_indices_] = True\n",
        "    labels = db.labels_\n",
        "\n",
        "    # Number of clusters in labels, ignoring noise if present.\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise = list(labels).count(-1)\n",
        "\n",
        "    print('Estimated number of clusters: %d' % n_clusters)\n",
        "    print('Estimated number of noise points: %d' % n_noise)\n",
        "    print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(sim, labels, metric = 'precomputed'))\n",
        "    \n",
        "    plotSilhouette(sim, n_clusters, labels)\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOsOIf6s17kq"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSmWx0EI17kq"
      },
      "source": [
        "disch_chaps = pd.read_csv('discharge_chapters_simple.csv', usecols = ['Blood/Immune', 'Circulatory', \"Abnormal\", \"Musculoskeletal\", \"Genitourinary\", \"Nutritional\", \"Nervous\", \"Respiratory\", \"Digestive\"]).applymap(lambda x:1 if x >= 1 else 0)\n",
        "disch_chaps.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSW_A10E17kt"
      },
      "source": [
        "other_features = pd.read_csv('combined_clean.csv', usecols = ['id', 'ICU', 'death', 'Oxygen therapy - face mask', 'Oxygen therapy - high flow', 'Oxygen therapy - ventilator', 'Oxygen therapy - intubation', 'ECMO', 'Noninvasive ventilation', 'Invasive ventilation', 'Methylprednisolone', 'Norepinephrine', 'los']).fillna(0)\n",
        "other_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYabpfcG17ku"
      },
      "source": [
        "oxygen_therapies = pd.DataFrame(columns = ['Oxygen therapy - noninvasive', 'Oxygen therapy - invasive'])\n",
        "oxygen_therapies['Oxygen therapy - noninvasive'] = (other_features['Oxygen therapy - face mask'] + other_features['Oxygen therapy - high flow'] + other_features['Noninvasive ventilation']) > 0\n",
        "oxygen_therapies['Oxygen therapy - invasive'] = (other_features['Oxygen therapy - intubation'] + other_features['Oxygen therapy - ventilator'] + other_features['Invasive ventilation']) > 0\n",
        "oxygen_therapies = oxygen_therapies.applymap(lambda x: 1 if x else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dq0cegH17ku"
      },
      "source": [
        "data = pd.concat([disch_chaps, other_features[['ICU', 'death']], oxygen_therapies, other_features[['ECMO', 'los']]], axis = 1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBkK-aEj17kw"
      },
      "source": [
        "sim = similarity_matrix(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqmjXJ3d17kx"
      },
      "source": [
        "sns.heatmap(sim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmyQaV_Y17ky"
      },
      "source": [
        "sim.max().max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gst-gzYE17ky"
      },
      "source": [
        "chooseEps(sim, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v1ZAEn117kz"
      },
      "source": [
        "tuneEps(sim, [0.1, 0.2, 0.3, 0.4, 0.45, 0.5], 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nBZTnD317kz"
      },
      "source": [
        "clusters = applyDBScan(sim, 0.45, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkkPvH7E17kz"
      },
      "source": [
        "id_nums = pd.read_csv('discharge_chapters_simple.csv', usecols = ['id'], squeeze = True).tolist()\n",
        "dbscan_clusters = pd.DataFrame({'id':id_nums, 'clusters_9':clusters})\n",
        "dbscan_clusters.to_csv('dbscan_clusters.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
